{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ld use a generator to load data and preprocess it on the fly, in batch size portions to feed into your Behavioral Cloning model .\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('mydata/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "with open('second track/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from numpy.random import shuffle\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #count = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = 'mydata/IMG/'+batch_sample[0].split('\\\\')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                if center_image is None:\n",
    "                    name = 'second track/IMG/'+batch_sample[0].split('\\\\')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                #image loading check\n",
    "                if center_image is None:\n",
    "                    print(\"Image loading failed\")\n",
    "                \n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(cv2.flip( center_image, 1 ))    \n",
    "                angles.append(-center_angle)\n",
    "            #print(images[0])\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            #count += len(images)\n",
    "            #print(count)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "#train_count = 0\n",
    "#test_count = 0\n",
    "#tgen = generator(train_samples[1:], batch_size=32)\n",
    "#vgen = generator(validation_samples[1:], batch_size=32)\n",
    "#for g1, count1 in tgen:\n",
    "#    train_generator = g1\n",
    "#    train_count = count1\n",
    "#for g2, count2 in vgen:\n",
    "#    validation_generator = g2\n",
    "#    test_count = count2\n",
    "\n",
    "train_generator = generator(train_samples[1:32], batch_size=32)\n",
    "validation_generator = generator(validation_samples[1:32], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2, activity_l2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "name = 'mydata/IMG/'+samples[1][0].split('\\\\')[-1]\n",
    "image = cv2.imread(name)\n",
    "crop_top = 50\n",
    "crop_bottom = 20\n",
    "shape = (image.shape[0]-(crop_top+crop_bottom), image.shape[1], image.shape[2])\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLenetModel():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((crop_top,crop_bottom), (0,0)), input_shape=image.shape))\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1., input_shape=shape))\n",
    "    model.add(Convolution2D(6, 5, 5,border_mode='valid', activation='elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(6, 5, 5,border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(6, 5, 5,border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNvidiaModel():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((crop_top,crop_bottom), (0,0)), input_shape=image.shape))\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1., input_shape=shape))\n",
    "    model.add(Convolution2D(24, 5, 5,border_mode='valid',subsample=(2,2), activation='elu', W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(36, 5, 5,border_mode='valid', subsample=(2,2), activation='elu', W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(48, 3, 3,border_mode='valid', subsample=(2,2), activation='elu', W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(64, 3, 3,border_mode='valid', subsample=(2,2), activation='elu', W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(256, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(64, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(16, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runModel(model, filename):    \n",
    "    history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "        len(train_samples), validation_data = \n",
    "        validation_generator,\n",
    "        nb_val_samples = len(validation_samples), \n",
    "        nb_epoch=1, verbose=1)\n",
    "\n",
    "    # Save model data\n",
    "    model.save(filename+'.h5')\n",
    "    json_string = model.to_json()\n",
    "    with open(filename +'.json', 'w') as f:\n",
    "        f.write(json_string)\n",
    "\n",
    "    ### plot the training and validation loss for each epoch\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.plot(history_object.history['val_loss'])\n",
    "    plt.title('model mean squared error loss')\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running nvidia model\n",
      "Epoch 1/6\n",
      " 3658/12184 [========>.....................] - ETA: 253s - loss: 3.3439"
     ]
    }
   ],
   "source": [
    "# run nvidia model\n",
    "model = getNvidiaModel()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "print(\"Running nvidia model\")\n",
    "runModel(model, 'nmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run lenet model\n",
    "model1 = getLenetModel()\n",
    "model1.compile(loss='mse', optimizer='adam')\n",
    "print(\"Running lenet model\")\n",
    "runModel(model1, 'lmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
